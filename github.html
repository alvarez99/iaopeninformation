<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <script src="https://kit.fontawesome.com/245c3c2022.js" crossorigin="anonymous"></script>
    <link rel="stylesheet" href="css/style.css" href="css/opinionated.css" href="css/normalize.css">
    <title>Home - IAopeninformation</title>
</head>
<body>
 <header class="header">

    <div class="container_header" >
       
        <div class="logo">
            <img width="100%" height="100%" src="./img/IA.png" alt="">
        </div>
        
        <div class="menu">
            <nav>
                <ul>
                    <li><a href="./index.html">Inicio</a></li>
                    <li><a href="./github.html">Github</a></li>
                    <li><a href="./videos.html">Videos</a></li>
                    <li><a href="./contacto.html">Contacto</a></li>
                    <li><a href="./Info.html">Informacion</a></li>
                </ul>
            </nav>
        </div>
        <i class="fa-solid fa-bars" id="icon_menu"></i>

        <div class="register">
            <button onclick="gotoLink(this)"  class="button_register"  value="./login.html">Registrarse</button>
            <script>
                function gotoLink(link){
                    console.log(link.value);
                    location.href = link.value;

                }
             </script>
        </div>


    </div>

 </header>
 
 <main>
    <div class="contenedor">
        
    
        <article>
            <h2>Repositorios github </h2>
            <h2 class="subtitle">GPT-3</h2>
            <p>Generative Pre-trained Transformer 3, conocida por sus siglas, es un modelo de lenguaje autorregresivo que emplea aprendizaje profundo para producir textos que simulan la redacción humana. Es la tercera generación de los modelos de predicción de lenguaje perteneciente a la serie GPT, creados por OpenAI, un laboratorio de investigación de inteligencia artificial con sede en San Francisco. La versión completa de GPT-3 tiene una capacidad de 175.000 millones de parámetros de aprendizaje automatizado, lo cual supera la magnitud de su predecesor, GPT-2. GPT-3 fue introducido en mayo de 2020 y, hasta julio de 2020, se encontraba en fase beta. Es parte de una tendencia en sistemas de procesamiento de lenguaje natural basados en "representaciones de lenguaje pre-entrenadas".Previo a la liberación de GPT-3, el modelo de lenguaje más grande era Turing NLG desarrollado por Microsoft, presentado en febrero de 2020, con una capacidad diez veces menor que el de GPT-3.</p><br />
            <p><a href="https://github.com/openai/gpt-3.git">Ir al repositorio</a></p>
        </article>

        <article>
            <h2 class="subtitle">Whisper</h2>
            <p>Whisper es un modelo de reconocimiento de voz de propósito general. Está entrenado en un gran conjunto de datos de audio diverso y también es un modelo multitarea que puede realizar reconocimiento de voz multilingüe, así como traducción de voz e identificación de idiomas.</p><br />
            <p><a href="https://github.com/openai/whisper.git">Ir al repositorio</a></p>
        </article>
    </div>
  
 
</main>

<script src="./js/script.js"></script>

</body>
</html>